{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7b3d7b",
   "metadata": {},
   "source": [
    "\n",
    "# データ構造化事例　＃２\n",
    "## 粉末・薄膜用のXRDデータのデータ構造化 \n",
    "\n",
    "\n",
    "\n",
    "**対応機種** ：　 リガク　SmartLab  \n",
    "**rawデータ**：　ras (テキスト形式)  \n",
    "**スクリプトの内容**：  \n",
    "主に粉体・薄膜用のXRD測定に用いられるリガク（SmartLab）のデータについて，データ構造化（数値csvファイル化）ならびに回折図を出力します．\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/38028745/134605660-c22bdca9-51f9-463b-8e59-83765d38a2d6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4600b6",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67c4e8d",
   "metadata": {},
   "source": [
    "## はじめに　Google ColabでGitHubのコードを動かす準備　（Google Colabでなければ不要）\n",
    "Google ColabでGitHubのコードを動かすための方法です．  \n",
    "**Google Colabからではない場合には本作業はスキップ**してください．  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc487e66",
   "metadata": {},
   "source": [
    "次のボタンを押してGoogle Colabにアクセスします．  \n",
    "もしグレーアウトで開かない場合には**右クリック**で「**新しいタブで開く**」を選んで進んでください．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7491989b",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ARIM-Japan/Training_Program/blob/main/XRD_Rigaku_Smartlab_Training.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c4ae6",
   "metadata": {},
   "source": [
    "## サンプルデータを読み込みましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c87c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shigeyuki Matsunami\\Dropbox\\4_データ設計\\1_データ構造化\\Github\\Training_Program\\Training_Program\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Training_Program'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ARIM-Japan/Training_Program.git\n",
    "%cd Training_Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5651aed7",
   "metadata": {},
   "source": [
    "これで準備が整いました．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a0f55",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c4945a",
   "metadata": {},
   "source": [
    "## 1. ライブラリーを読み込みましょう\n",
    "最初にコードを走らせるのに必要なライブラリーを読み込みます．ライブラリとしては以下を使っています．\n",
    " * 標準ライブラリー: ``glob``, ``os``, ``csv``\n",
    " * 数値処理用: ``pandas``\n",
    " * 可視化用: ``matplotlib``  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305a0929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイル操作用\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# 数値処理用\n",
    "import pandas as pd\n",
    "from chardet import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ccc64",
   "metadata": {},
   "source": [
    "また，出力結果を「output」フォルダーに保存するため，そのフォルダーの作成をします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be11d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'output'\n",
    "os.makedirs(output_folder,exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d23d8c",
   "metadata": {},
   "source": [
    "## 2. ファイルの拡張子を調べます\n",
    "データ構造化の最初のステップとして，データ構造化するファイルを特定する必要があります．その特定は**拡張子**で判定します．  \n",
    "下記の``read_files``関数は入力ファイルが置いてある「data」フォルダーにある特定の拡張子のファイルをすべてリスト化します．ここでは単一のファイルではなく複数のファイルが扱えることを想定しています．\n",
    "\n",
    "もしエラーがでたら「data」フォルダーを作成し，その中に.txtファイルを配置してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76104440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行処理#rawデータの読み込み\n",
    "def read_files(extension):\n",
    "    \"\"\"\n",
    "    概要: 特定の拡張子のついたファイルをすべて読み込む\n",
    "    @param extension: 読み込む拡張子\n",
    "    @return ソートされたファイル名群\n",
    "    \"\"\"\n",
    "\n",
    "    #入力データのフォルダーを\"data\"とする\n",
    "    data_folder = 'data/*'\n",
    "    path = data_folder + extension\n",
    "    \n",
    "    # 連続撮影されたファイル名の確認\n",
    "    files = glob.glob(path)\n",
    "    \n",
    "    input_files = sorted(files)\n",
    "    print (input_files)\n",
    "    \n",
    "    return input_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6993d9f5",
   "metadata": {},
   "source": [
    "SEMで撮影された撮影情報ファイルである.txtを含むファイルを指定してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e254d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\タンポポ花粉-１_1200倍(x1.2k).txt', 'data\\\\タンポポ花粉-１_200倍(x200).txt', 'data\\\\タンポポ花粉-１_600倍(x600).txt']\n"
     ]
    }
   ],
   "source": [
    "extension = '.txt'\n",
    "files = read_files(extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f9a63",
   "metadata": {},
   "source": [
    "上記のようにリスト配列の結果がソートされて戻ります． "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2edb8",
   "metadata": {},
   "source": [
    "# 3. 撮影メタデータを辞書化する\n",
    "\n",
    "データ構造化では，ファイルに含まれいているヘッダー部と数値部を切り離す処理をします．その切り離す場所を判定するために特定の文字（単語）を指定する方法をとります．そのようなときに**特定の単語が現れる「行数」を判定**する関数です．\n",
    "\n",
    "行判定は，次のような流れです．\n",
    "1. ``open``関数で読みだしたファイルをtextに格納．\n",
    "1. forループで一行づつtextを読み出しながら指定した文字（**word**）が含まれているかを``inキーワード``で判定\n",
    "1. 一致した行をmatch_lineに格納\n",
    "1. match_lineを戻し値としてreturnする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6fcb51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypara(_fn):\n",
    "\n",
    "    \"\"\"\n",
    "    概要: KEYPARAFILEのcsvを読み込みメタデータを翻訳する\n",
    "    @param _fn: templateファイル\n",
    "    @return：　変換した語彙の辞書を辞書型として\n",
    "    \"\"\"\n",
    "    \n",
    "    _dict = dict()\n",
    "\n",
    "    try:\n",
    "        with open(_fn, mode='r') as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                str = line.strip().split(',')\n",
    "                key = str[0].strip()\n",
    "                value = str[1].strip()\n",
    "                _dict[key] = value\n",
    "                line = f.readline()\n",
    "    except:\n",
    "        print('get_keypara NG', file=sys.stderr)\n",
    "\n",
    "    return _dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c54783a",
   "metadata": {},
   "source": [
    "\n",
    "予めcsvでまとめたキーパラメータのリスト``keypara.csv``を定義して次のように走らせます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa50e462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'InstructName': 'Instrument Model',\n",
       " 'SerialNumber': 'Instrument S/N',\n",
       " 'DataNumber': 'Comment and Number',\n",
       " 'ImageName': 'File Name',\n",
       " 'Date': 'Measurement Date',\n",
       " 'Time': 'Measurement Time',\n",
       " 'DataSize': 'Data Size',\n",
       " 'PixelSize': 'Pixel Size',\n",
       " 'SignalName': 'Signal Name',\n",
       " 'AcceleratingVoltage': 'Accelerating Voltage',\n",
       " 'Magnification': 'Magnification',\n",
       " 'WorkingDistance': 'Working Distance'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYPARAFILE = 'keypara.csv'\n",
    "keypara = get_keypara(KEYPARAFILE)\n",
    "keypara"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ebcbd",
   "metadata": {},
   "source": [
    "上記のようにリスト配列の結果が戻ります．  \n",
    "１つ目は「data」フォルダーにある.rasのファイル名（相対パス形式），２つ目はファイル数，３つ目は拡張子（.ras）を省いたファイル名です．  \n",
    "３番目はグラフのタイトルや出力ファイル名で使うために準備します．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f8120",
   "metadata": {},
   "source": [
    "# 4. ファイルの記述形式をcsv型に変える\n",
    "データ構造化では，ファイルに含まれいているヘッダー部と数値部を切り離す処理をします．その切り離す場所を判定するために特定の文字（単語）を指定する方法をとります．そのようなときに**特定の単語が現れる「行数」を判定**する関数です．\n",
    "\n",
    "行判定は，次のような流れです．\n",
    "1. ``open``関数で読みだしたファイルをtextに格納．\n",
    "1. forループで一行づつtextを読み出しながら指定した文字（**word**）が含まれているかを``inキーワード``で判定\n",
    "1. 一致した行をmatch_lineに格納\n",
    "1. match_lineを戻し値としてreturnする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0049ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ini_to_csv(_fn):\n",
    "    \"\"\"\n",
    "    概要: ini形式のtextファイルをcsv型へ変換する\n",
    "    @param _fn: rawデータのファイル\n",
    "    @return：　csv型をtxtとして戻す\n",
    "    \"\"\"\n",
    "    \n",
    "    csv = \"\"\n",
    "    \n",
    "    # encodingの判定\n",
    "    with open(_fn, 'rb') as f:\n",
    "        b = f.read()\n",
    "        enc = detect(b)\n",
    "        encd = enc['encoding']\n",
    "\n",
    "    with open(_fn, mode='r', encoding=encd) as f:\n",
    "        line = f.readline()\n",
    "        \n",
    "        while line:\n",
    "            if not re.match(u\"\\[\", line):\n",
    "                str = line.rstrip(os.linesep).replace('=', ',', 1)\n",
    "                csv += str\n",
    "                csv += \"\\n\"\n",
    "            line = f.readline()\n",
    "            \n",
    "    return csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd3f0c",
   "metadata": {},
   "source": [
    "ここでは「2. ファイルの拡張子を調べます」で出力したdataフォルタにある「XRD_RIGAKU.ras」について”＊RAS_INT_START”という文字（列）が含まれる行数を調べてみることにしましょう．  \n",
    "\n",
    "単語判定ではword = '＊RAS_INT_START'として変数としておくと，関数には読み込みやすくなります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8790c127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InstructName,TM4000\\nSemVersion,01-08\\nSDMVersion,\\nSerialNumber,2170A6-05\\nDataNumber,TM4000 0001\\nSampleName,\\nFormat,tif\\nImageName,タンポポ花粉-１_1200倍(x1.2k).tif\\nDirectory,D:\\\\SemImage\\\\lixianglan\\\\\\nDate,2021/06/23\\nTime,16:43:33\\nMedia,HD[Data]\\nDataSize,1280x960\\nPixelSize,82.68229\\nSignalName,BSE\\nDisplaySignalName,BSE\\nSEDetSetting,\\nAcceleratingVoltage,15000 Volt\\nDecelerationVoltage,0 Volt\\nDecelerationMode,\\nMagnification,1200\\nWorkingDistance,7920.5 um\\nEmissionCurrent,46900 nA\\nPhotoSize,1000\\nMagnificationDisplay,0\\nVacuum,50\\nMicronMarker,40000\\nSubMagnification,0\\nSubSignalName,\\nSpecimenBias,0 V\\nCondencer1,9230\\nScanSpeed,Capture_Slow(80)\\nCaptureSpeed_Integration,\\nCalibrationScanSpeed,24\\nImgEnhance,0\\nColorMode,Grayscale\\nColorPalette,\\nScreenMode,Full Screen\\nComment,\\nKeyWord1,\\nKeyWord2,\\nCondition,Vacc=15.0kV Mag=x1.20k WD=7.9mm LensMode=3\\nDataDisplayCombine,1\\nStageType,0\\nStagePositionX,17500000\\nStagePositionY,17500000\\nStagePositionR,0.000\\nStagePositionZ,0\\nStagePositionT,0.000\\nFocusDepth,\\nDynamicFocus,0\\nTiltCompensation,0\\nImageShiftX,\\nImageShiftY,\\nRasterRotation,10.2\\nMagneticSample,\\nUserName,***\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"data\\\\タンポポ花粉-１_1200倍(x1.2k).txt\"\n",
    "txt = ini_to_csv(filename)\n",
    "txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e0e69",
   "metadata": {},
   "source": [
    "上記のように”469”という数字が現れました．これは'RAS_INT_START'という文字列（単語）が469行目にあることを示しています．（注意：pythonは0行からカウントが始まるため，1行目カウントであれば470行目となります）  \n",
    "\n",
    "実は，この”RAS_INT_START”はリガクの.rasファイルをみると，数値部が始まる直前の単語であることがわかります．そうです．470行目からの数値部が回折角に対する強度データとなりますので，そのための判定に使っています．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3be93",
   "metadata": {},
   "source": [
    "では，XRD_RIGAKU.rasを直接指定してみましょう．dataframe形式で数値部が表示されます．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e45fd8",
   "metadata": {},
   "source": [
    "## 5. 数値化csvファイルの保存\n",
    "上記のdataとして出力したdataframeをcsv化します．ファイルの保存は``pandas``の``to_csv``関数を使います．ここでは，\"output\"というフォルダに\"test_extract.csv\"というファイル名で保存します．\n",
    "\n",
    "その時，``index =false``とすることで行番号（インデックス番号）の出力を不要としています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d1dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metatable (files,keypara):\n",
    "    \n",
    "    # 撮影メタデータの抽出\n",
    "    n = 1\n",
    "    for fn in files:\n",
    "        txt = \"\"\n",
    "        txt = ini_to_csv(fn)\n",
    "        \n",
    "        tmp = pd.read_csv(io.StringIO(txt), header=None,\n",
    "                          names=['key', 'value%s' % n])\n",
    "        if n == 1:\n",
    "            out = tmp\n",
    "        else:\n",
    "            out = pd.merge(out, tmp, on='key', how='outer')\n",
    "        n += 1\n",
    "        \n",
    "    out = out.set_index('key')\n",
    "    out = out.transpose()\n",
    "    out = out[list(keypara.keys())]\n",
    "    d = dict(zip(list(keypara.keys()), list(keypara.values())))\n",
    "    out = out.rename(columns=d)\n",
    "\n",
    "    # 単位削除\n",
    "    for index, row in out.iterrows():\n",
    "        for k in ['Accelerating Voltage', 'Working Distance']:\n",
    "            v = row[k]\n",
    "            if v == v:\n",
    "                v = v.split(' ')\n",
    "                if len(v) > 1:\n",
    "                    row[k] = v[0]\n",
    "\n",
    "    # リストの出力\n",
    "    out.to_csv('output/' + \"metalist.csv\", index = None,\n",
    "               quoting=csv.QUOTE_NONNUMERIC, encoding='utf_8_sig')\n",
    "    return print ('make meta-list file')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fe85a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make meta-list file\n"
     ]
    }
   ],
   "source": [
    "filename = \"data\\\\タンポポ花粉-１_1200倍(x1.2k).txt\"\n",
    "keypara = keypara\n",
    "make_metatable (files,keypara)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d18d09b",
   "metadata": {},
   "source": [
    "ここでは，第一引数として\"data\"とし，第二引数を＝”XRD_RIGAKU”として走らせることにしましょう．\n",
    "なお，上記の最終行に``savefig``が見て取れるかと思います．ここで.pngの可視図を”output”フォルダーに保存していますのであわせて確認してみてください．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a743a",
   "metadata": {},
   "source": [
    "## 7. 一本化する\n",
    "上記の一連の処理を一本化することをします．下記のように一本化したコードを``main``関数として定義しておきます．処理の順番を並べるだけです．\n",
    "また，上記ではファイルが一つだけを想定していました．下記の``main``では複数の.rasファイルがある場合にでも実行できるよう``for``ループにしています．\n",
    "\n",
    "計測では複数ファイルを一括して処理する場合がほとんどですので，このような一連の処理は``for``ループ化しておくと作業効率化に効いてきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74427d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    output_folder = 'output'\n",
    "    os.makedirs(output_folder,exist_ok = True)\n",
    "    \n",
    "    extension = '.txt'\n",
    "    files = read_files(extension)\n",
    "    \n",
    "    KEYPARAFILE = 'keypara.csv'\n",
    "    keypara = get_keypara(KEYPARAFILE)\n",
    "    \n",
    "    \n",
    "    make_metatable(files,keypara)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1c4527",
   "metadata": {},
   "source": [
    "その``main``関数を下記のようにして走らせてみましょう．一連の処理が一貫で行われます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a2e159c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\タンポポ花粉-１_1200倍(x1.2k).txt', 'data\\\\タンポポ花粉-１_200倍(x200).txt', 'data\\\\タンポポ花粉-１_600倍(x600).txt']\n",
      "make meta-list file\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737751e4",
   "metadata": {},
   "source": [
    "## おわりに\n",
    "このXRDは最も基本形のシンプルなタイプのデータ構造化の事例となります．基本的なポイントとなるのは次の処理項目です．\n",
    "\n",
    "* データ構造化したいファイルを指定して読み込む\n",
    "* 必要な数値部を抽出し保存する\n",
    "* 数値部から可視化図を作成して保存する\n",
    "\n",
    "あとは，お好みに応じて``make_figure``関数の設定を触りながらオリジナルのデザインを進めてゆくことで調整します．ここは``matplotlib``の勉強のたたき台にもなるかと思います．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
